<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="/"/>
    <title>Distant Reading the VICE Code Base</title>

    <meta name="generator" content="pandoc" />
        
    <link rel="stylesheet" href="/assets/templates/archive.css">

</head>
<body>

    <nav role="navigation">
        <ul class="nav-h">
            <li><a target="_self" href="/">Home</a></li>
	        <li><a target="_self" href="/notes/Journal.html">Journal</a></li>
	        <li><a target="_self" href="/notes/Notes.html">Notes</a></li>
	        <li><a target="_self" href="/notes/Glossary.html">Glossary</a></li>
        </ul>

    </nav>

    <main role="main">
        <h1 id="distant-reading-the-vice-code-base">Distant Reading the
        VICE Code Base</h1>
        <h2 id="journal">Journal</h2>
        <h3 id="section">2023-05-07</h3>
        <h3 id="basic-voyant-tools-setup">Basic Voyant Tools setup</h3>
        <ul>
        <li>If you work on a corpus and change the settings, remember to
        <a
        href="https://voyant-tools.org/docs/#!/guide/start-section-bookmarking-your-corpus">bookmark
        (export) your current state</a> to access it later again</li>
        <li>Running Voyant Tools locally isn’t strictly necessary, but
        it improved speed in my case
        <ul>
        <li>Setup Voyant Server <a
        href="https://voyant-tools.org/docs/#!/guide/server">according
        to the guide</a></li>
        <li>I Ran into problems on launching VoyantServer on macOS; had
        to give the Java Runtime Environment <strong><a
        href="https://discussions.apple.com/thread/254608797">Full Disk
        Access</a></strong> and start the server via <a
        href="https://brogramo.com/java-application-launch-failed-check-console-for-possible-error-message/">shell</a></li>
        </ul></li>
        <li>Copied all <code>.c</code> and all <code>.h</code> files
        from the <code>src</code> folder into a new Voyant project
        (ignore the import warning). This also means I flattened the
        hierarchy in which the files were organized. I believe this to
        be neglectable in the case of VICE</li>
        <li>Deactivate <a
        href="https://voyant-tools.org/docs/#!/guide/stopwords">stopwords</a>,
        since in code every word can have meaning and is not just
        syntactic glue</li>
        <li>Add <a
        href="https://voyant-tools.org/docs/#!/guide/categories">categories</a>
        and colour-coded them</li>
        </ul>
        <h3 id="stopwords-and-categories-for-c">Stopwords and categories
        for C</h3>
        <p>Here is a list of relevant stopwords generated by ChatGPT or
        Github Codepilot, provided by Moritz Mähr.</p>
        <ul>
        <li>Data Types
        <ul>
        <li>char , double , float , int , long , short , signed ,
        unsigned , void , _Bool</li>
        </ul></li>
        <li>Control Flow Keywords
        <ul>
        <li>break, continue, do, else, for, goto, if, return, switch,
        while</li>
        </ul></li>
        <li>Storage Class Keywords
        <ul>
        <li>auto, extern, register, static, typedef</li>
        </ul></li>
        <li>Type Qualifiers
        <ul>
        <li>const, restrict, volatile</li>
        </ul></li>
        <li>Other Keywords
        <ul>
        <li>_Alignas, _Alignof, _Atomic, _Complex, _Generic, _Imaginary,
        _Noreturn, _Static_assert, _Thread_local</li>
        </ul></li>
        </ul>
        <h3 id="to-look-into">To look into</h3>
        <ul>
        <li>Categories (Keywords, Comments etc.)</li>
        <li>Contexts word sequences: <a
        href="https://voyant-tools.org/docs/#!/guide/collocatesgraph">collocates
        graph</a> , <a
        href="https://voyant-tools.org/docs/#!/guide/corpuscollocates">corpus
        collocates</a> , <a
        href="https://voyant-tools.org/docs/#!/guide/contexts">contexts</a> , <a
        href="https://voyant-tools.org/docs/#!/guide/phrases">phrases</a> , <a
        href="https://voyant-tools.org/docs/#!/guide/wordtree">wordtree</a></li>
        <li><a
        href="https://voyant-tools.org/docs/#!/guide/topics">Topics</a> and <a
        href="https://voyant-tools.org/docs/#!/guide/trends">trends</a></li>
        </ul>
        <h3 id="section-1">2023-05-17</h3>
        <p>After a rather messy start with the complete corpus, I wanted
        to have a go at just the comments. I tried my luck with regex
        and search and replace, first in vscodium, then in a bash
        onliner (with find and sed) to remove everything that is not a
        comment. Spent a few hours on this problem without much luck,
        mainly because vscodium couldn’t handle search and replace and
        several thousand files. I reverted to working with python and
        asked ChatGPT to produce me a script that solved my problem…</p>
        <p>My prompt
        “<code>I need a python script that goes through a folder with files, searches through them with a regex pattern and copies the matches into new files</code>”
        resulted in a proposition which I needed to tweak a bit to work
        as intended. That took me 20 minutes in the end.</p>
        <h4 id="python-script">Python script</h4>
        <p>Splits VICE source code into comments and code</p>
        <ul>
        <li><a
        href="https://github.com/thgie/critical-reading-vice">Source
        Code for the computational analysis</a><br><a
        href="https://doi.org/10.5281/zenodo.8103760"><img
        src="https://zenodo.org/badge/DOI/10.5281/zenodo.8103760.svg"
        alt="DOI" /></a></li>
        </ul>
        <p>I already had the regex pattern in place. After the clean-up,
        I loaded everything into a new corpus and started to play a bit.
        It indicates that I don’t have much experience with text mining,
        but at least it already seemed more meaningful. This new corpus,
        based just on the comment, will be the starting point for a
        later exploration.</p>
        <h3 id="section-2">2023-05-24</h3>
        <p>I worked on the python script to also remove the licence from
        the text files. Since they have been present in every document,
        they clogged up Voyant Tools with their presence. The script
        block in the former log entry is updated accordingly. Spinning
        up Voyant with this cleaned up corpus feels at least like a
        proper text.</p>
        <p>Not advancing with reading the corpus through Voyant Tools.
        The comments are heavily segmented and include plenty of
        technical terms. Often the comments are brief and referential,
        respectively, again coded. Examples include what type a function
        is – peek, open, init, close, store, read, reset, and my
        favourite the “NO poke function”.</p>
        <p><strong>What style and what intent drives a comment?</strong>
        Of course brevity and precision, but many comments wouldn’t fit
        one or the other. Some comments indicate what should happen, or
        comment the process along the lines of code.</p>
        <blockquote>
        <p>detect 35..42 track d64 image, determine image
        parameters.<br> Walk from 35 to 42, calculate expected image
        file size for each track,<br> and compare this with the size of
        the given image. <br> start at track 35 <br> check if image
        matches “checkimage_tracks” <br> image file matches
        size-with-no-error-info <br> image file matches
        size-with-error-info <br> try next track (all tracks from 35 to
        42 have 17 blocks) <br> we tried them all up to 42, none worked,
        image must be corrupt</p>
        </blockquote>
        <p>Then again, other comments tell little stories.</p>
        <blockquote>
        <p>HACK: if the image has an error map, and the “FDC” did not
        detect an<br> error in the GCR stream, use the error from the
        error map instead.<br> FIXME: what should really be done is
        encoding the errors from the<br> error map into the GCR stream.
        this is a lot more effort and will<br> give the exact same
        results, so i will leave it to someone else :)</p>
        </blockquote>
        <p>There are also strong indications that different authors
        follow different comment styles and approaches.</p>
        <p>Maybe I’ll research around VICE next to get a better picture.
        Since critical code analysis is an interpretative method, it
        “requires reading an object in its (post)human context through a
        particular critical lens.” (Marino, 2012, p. 15) Community,
        history, but also the embedded values and frame of reference
        will be important.</p>
        <h3 id="section-3">2023-06-07</h3>
        <ul>
        <li>A large problem in reading source code as literary text is
        that it is not easy to sort in a linear way, which in turn makes
        it hard to generate meaningful patterns. Capturing thoughts on
        that in <a href="notes/Source%20Code%20as%20Text.html">Source Code
        as Text</a></li>
        </ul>
        <h3 id="section-4">2023-06-12</h3>
        <p>Expanded <a href="/notes/Distant Reading the VICE Code Base.html#python%20script">python script</a> to
        split into comments and into code files.</p>
        <p>By reading through <a
        href="literature/holtgenShiftRestoreEscapeRetrocomputingUnd2014.html">André
        Fachats insightful text on aspects of the VICE emulator</a> I
        learned that the V in VICE stands for versatile. That means the
        emulator incorporates several different Commodore hardware
        configurations. I guess, this makes it even harder to process
        meaningful information through distant reading. A graph based
        approach would be interesting, but then it is definitely not a
        textual reading anymore.</p>
        <h3 id="section-5">2023-06-18</h3>
        <p>I followed my last insight and tried to have a look at the
        VICE source code corpus through the eyes of <a
        href="https://gephi.org/">Gephi</a>, which is a tool for network
        visualisations. I produced two new python scripts. The first
        script is attempting extracting the relations between the source
        code files by looking for <code>#includes</code>. The second
        extracts the relation between authors and on which files they
        worked.</p>
        <h4
        id="relations-between-source-code-files-as-well-as-between-authors-and-source-code-files">Relations
        between source code files as well as between authors and source
        code files</h4>
        <ul>
        <li><a
        href="https://github.com/thgie/critical-reading-vice">Source
        Code of the computational analysis</a><br><a
        href="https://doi.org/10.5281/zenodo.8103760"><img
        src="https://zenodo.org/badge/DOI/10.5281/zenodo.8103760.svg"
        alt="DOI" /></a></li>
        </ul>
        <h4 id="visualization-of-the-two-networks">Visualization of the
        two networks</h4>
        <h5 id="relations-between-files">Relations between files</h5>
        <p><img src="assets/Sourcecode.png" /></p>
        <h5 id="relations-between-author-and-source-files">Relations
        between author and source files</h5>
        <p><img src="assets/Authors.png" /></p>
        <h4 id="quick-insights">Quick Insights</h4>
        <p>The network between the source files, through acts of
        <code>#include</code>, reveals a hot mess. There is no way of
        bringing this corpus into a linear order. There were 2839 nodes
        and, 19463 edges. Such a corpus needs to be treated as a
        hypertext, but I have no idea right now, how to extract
        meaningful distant readings from such a thing. Nevertheless, it
        confirmed my assumptions about the non-linearity of the source
        code. I probably should have thought of that earlier…</p>
        <p>The authors networked had 2590 nodes and 3390 edges. In
        contrast to the source code files networked, this visualization
        leads to the clear insight, that just a handful of people
        developed the majority of the code base, with around five to ten
        key players. In a quick check, I could figure out that more than
        half of the key players are not listed as “current developers”
        any more. It is also the key players who collaborated on files,
        while also having many areas on their own. I believe a
        clustering by functional area within the VICE emulator could be
        interesting here.</p>
        <h2 id="related">Related</h2>
        <ul>
        <li><a href="notes/Source%20Code%20as%20Text.html">Source Code as
        Text</a></li>
        <li><a href="notes/Emulation.html">Emulation</a></li>
        </ul>
    </main>

    <footer class="text-sm">
        <p class="flex">
        </p>
        <p>All content, where not noted otherwise on <a href="https://dissertation.thgie.ch">dissertation.thgie.ch</a> is released and distributed under the <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode">CC-BY-SA 4.0 license</a>.</p>
    </footer>

    <script>

        document.addEventListener('DOMContentLoaded', () => {
            document.querySelectorAll('p').forEach(el => {
                if(el.querySelectorAll('img').length > 1) {
                    el.classList.add('gallery')
                }
            })
        })

    </script>
</body>
</html>
